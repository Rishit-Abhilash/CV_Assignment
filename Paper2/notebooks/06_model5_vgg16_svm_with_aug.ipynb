{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: VGG16-SVM-with-Aug\n",
    "\n",
    "## Transfer Learning: Pre-trained VGG16 + SVM\n",
    "\n",
    "**Architecture:** VGG16 (remove top) + SVM classifier\n",
    "- Uses pre-trained ImageNet weights\n",
    "- Linear SVM kernel\n",
    "- Input: 224×224×3\n",
    "\n",
    "**Target:** 98.67% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Device: cuda\n",
      "Configuration loaded successfully!\n",
      "\n",
      "Base path: C:\\Users\\rishi\\CV_Assignment\\Paper2\n",
      "Raw data path: C:\\Users\\rishi\\CV_Assignment\\Paper2\\Raw_Data\n",
      "Number of models: 5\n",
      "Data processing functions loaded successfully!\n",
      "Evaluation metrics functions loaded successfully!\n",
      "Visualization functions loaded successfully!\n",
      "Data augmentation setup loaded successfully!\n",
      "\n",
      "================================================================================\n",
      "PAPER 2 UTILITIES AND CONFIGURATION - SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ All libraries imported successfully\n",
      "✓ Configuration parameters loaded\n",
      "✓ Data processing functions defined\n",
      "✓ Evaluation metrics functions defined\n",
      "✓ Visualization functions defined\n",
      "✓ Data augmentation configured\n",
      "\n",
      "Ready to proceed with:\n",
      "  - Notebook 01: Data Preparation\n",
      "  - Notebooks 02-06: Model Implementations\n",
      "  - Notebook 07: Results Comparison\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "%run 00_utils_and_config.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 628. MiB for an array with shape (658409472,) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprocessed_data_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX_train_224.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m X_test = np.load(CONFIG[\u001b[33m\"\u001b[39m\u001b[33mprocessed_data_path\u001b[39m\u001b[33m\"\u001b[39m] / \u001b[33m\"\u001b[39m\u001b[33mX_test_224.npy\u001b[39m\u001b[33m\"\u001b[39m).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m y_train = np.load(CONFIG[\u001b[33m\"\u001b[39m\u001b[33mprocessed_data_path\u001b[39m\u001b[33m\"\u001b[39m] / \u001b[33m\"\u001b[39m\u001b[33my_train.npy\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rishi\\CV_Assignment\\cvvenv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:480\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    478\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    484\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rishi\\CV_Assignment\\cvvenv\\Lib\\site-packages\\numpy\\lib\\format.py:829\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[32m    828\u001b[39m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    831\u001b[39m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    832\u001b[39m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m    842\u001b[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 628. MiB for an array with shape (658409472,) and data type uint8"
     ]
    }
   ],
   "source": [
    "X_train = np.load(CONFIG[\"processed_data_path\"] / \"X_train_224.npy\").astype(\"float32\")\n",
    "X_test = np.load(CONFIG[\"processed_data_path\"] / \"X_test_224.npy\").astype(\"float32\")\n",
    "y_train = np.load(CONFIG[\"processed_data_path\"] / \"y_train.npy\")\n",
    "y_test = np.load(CONFIG[\"processed_data_path\"] / \"y_test.npy\")\n",
    "\n",
    "# Convert to PyTorch format (N, C, H, W)\n",
    "X_train = np.transpose(X_train, (0, 3, 1, 2)) / 255.0\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2)) / 255.0\n",
    "\n",
    "# Normalize using ImageNet stats for VGG16\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "X_train = (torch.from_numpy(X_train).float() - mean) / std\n",
    "X_test = (torch.from_numpy(X_test).float() - mean) / std\n",
    "\n",
    "print(f\"Data ready: {X_train.shape}, {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build VGG16 + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 from torchvision\n",
    "base_model = torchvision_models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in base_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier with SVM-like layer\n",
    "class VGG16SVM(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(VGG16SVM, self).__init__()\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = base_model.avgpool\n",
    "        # VGG16 outputs 512 * 7 * 7 = 25088 features\n",
    "        self.flatten_size = 25088\n",
    "        self.fc = nn.Linear(self.flatten_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, self.flatten_size)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = VGG16SVM(base_model, num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001, weight_decay=0.01)  # Only train classifier\n",
    "\n",
    "print(f\"Total params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train, torch.from_numpy(y_train).long())\n",
    "test_dataset = TensorDataset(X_test, torch.from_numpy(y_test).long())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "start_time = time.time()\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_model_path = str(CONFIG[\"saved_models_path\"] / \"model5_vgg16_svm_best.pth\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/10 - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = VGG16SVM(base_model, num_classes=2).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.eval()\n",
    "\n",
    "start_time = time.time()\n",
    "all_preds, all_probs = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "\n",
    "y_pred_proba = np.vstack(all_probs)\n",
    "y_pred = np.concatenate(all_preds)\n",
    "testing_time = (time.time() - start_time) * 1000\n",
    "\n",
    "metrics = calculate_all_metrics(y_test, y_pred, y_pred_proba[:, 1])\n",
    "print_metrics(metrics, \"Model 5: VGG16-SVM\")\n",
    "print(f\"Accuracy: {metrics['accuracy']*100:.2f}% (Target: 98.67%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, \"Model 5: VGG16-SVM\", CONFIG[\"results_path\"] / \"training_curves\" / \"model5_training.png\")\n",
    "torch.save(model.state_dict(), CONFIG[\"saved_models_path\"] / \"model5_vgg16_svm_final.pth\")\n",
    "results = {\"model_name\": \"VGG16-SVM-with-Aug\", \"accuracy\": float(metrics[\"accuracy\"]), \"precision\": float(metrics[\"precision\"]), \"recall\": float(metrics[\"recall\"]), \"f1_score\": float(metrics[\"f1_score\"]), \"training_time_seconds\": float(training_time), \"testing_time_ms\": float(testing_time)}\n",
    "with open(CONFIG[\"results_path\"] / \"model5_results.json\", \"w\") as f: json.dump(results, f, indent=2)\n",
    "print(\"✓ VGG16-SVM complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
