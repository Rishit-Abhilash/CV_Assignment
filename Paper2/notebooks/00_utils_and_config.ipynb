{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 2: Utilities and Configuration\n",
    "\n",
    "## Classification of Alzheimer's Disease using MRI Data Based on Deep Learning Techniques\n",
    "\n",
    "This notebook contains:\n",
    "- Configuration parameters for all 5 models\n",
    "- Helper functions for data processing\n",
    "- Evaluation metrics functions\n",
    "- Visualization utilities\n",
    "\n",
    "**Dataset:** OASIS-2 Raw MRI Data  \n",
    "**Models:** CNNs-without-Aug, CNNs-with-Aug, CNNs-LSTM-with-Aug, CNNs-SVM-with-Aug, VGG16-SVM-with-Aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "import nibabel as nib  # For reading NIfTI files\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Deep Learning - PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms, models as torchvision_models\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "\n",
      "Base path: C:\\Users\\rishi\\CV_Assignment\\Paper2\n",
      "Raw data path: C:\\Users\\rishi\\CV_Assignment\\Paper2\\Raw_Data\n",
      "Number of models: 5\n"
     ]
    }
   ],
   "source": [
    "# Global configuration matching Paper 2 specifications\n",
    "CONFIG = {\n",
    "    # Data paths\n",
    "    'base_path': Path('../'),  # Paper2 directory\n",
    "    'raw_data_path': Path('../Raw_Data/'),\n",
    "    'demographics_file': Path('../Raw_Data/OASIS_demographic.xlsx'),\n",
    "    'processed_data_path': Path('../processed_data/'),\n",
    "    'saved_models_path': Path('../saved_models/'),\n",
    "    'results_path': Path('../results/'),\n",
    "    \n",
    "    # Dataset parameters (from Paper 2)\n",
    "    'target_total_images': 6400,\n",
    "    'train_split': 0.80,  # 5120 images\n",
    "    'test_split': 0.20,   # 1280 images\n",
    "    'random_state': 42,\n",
    "    \n",
    "    # Binary classification\n",
    "    'num_classes': 2,\n",
    "    'class_names': ['Non-Demented', 'Demented'],\n",
    "    'cdr_threshold': 0.5,  # CDR >= 0.5 = Demented\n",
    "    \n",
    "    # Slice extraction from 3D volumes\n",
    "    'slices_per_volume': 4,  # Extract 4-5 representative slices\n",
    "    'slice_axis': 'axial',   # Axial slices (most common in AD studies)\n",
    "    \n",
    "    # Model-specific parameters (from Paper 2 Table 3)\n",
    "    'models': {\n",
    "        'cnn_without_aug': {\n",
    "            'name': 'CNNs-without-Aug',\n",
    "            'input_shape': (224, 224, 3),\n",
    "            'epochs': 100,\n",
    "            'batch_size': 30,\n",
    "            'learning_rate': 0.0001,\n",
    "            'optimizer': 'adam',\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'augmentation': False,\n",
    "            'total_params': 2129250,\n",
    "            'target_accuracy': 0.9922\n",
    "        },\n",
    "        'cnn_with_aug': {\n",
    "            'name': 'CNNs-with-Aug',\n",
    "            'input_shape': (128, 128, 3),\n",
    "            'epochs': 100,\n",
    "            'batch_size': 65,\n",
    "            'learning_rate': 0.0001,\n",
    "            'optimizer': 'adam',\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'augmentation': True,\n",
    "            'total_params': 6454626,\n",
    "            'target_accuracy': 0.9961\n",
    "        },\n",
    "        'cnn_lstm_with_aug': {\n",
    "            'name': 'CNNs-LSTM-with-Aug',\n",
    "            'input_shape': (1, 128, 128, 3),  # Time-distributed\n",
    "            'epochs': 25,\n",
    "            'batch_size': 16,\n",
    "            'learning_rate': 0.0001,\n",
    "            'optimizer': 'adam',\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'augmentation': True,\n",
    "            'lstm_units': 100,\n",
    "            'total_params': 11580858,\n",
    "            'target_accuracy': 0.9992  # BEST MODEL\n",
    "        },\n",
    "        'cnn_svm_with_aug': {\n",
    "            'name': 'CNNs-SVM-with-Aug',\n",
    "            'input_shape': (224, 224, 3),\n",
    "            'epochs': 20,\n",
    "            'batch_size': 32,\n",
    "            'learning_rate': 0.0001,\n",
    "            'optimizer': 'adam',\n",
    "            'loss': 'squared_hinge',  # For SVM compatibility\n",
    "            'augmentation': True,\n",
    "            'total_params': 206882,\n",
    "            'target_accuracy': 0.9914\n",
    "        },\n",
    "        'vgg16_svm_with_aug': {\n",
    "            'name': 'VGG16-SVM-with-Aug',\n",
    "            'input_shape': (224, 224, 3),\n",
    "            'svm_kernel': 'linear',\n",
    "            'augmentation': True,\n",
    "            'total_features': 14714688,\n",
    "            'target_accuracy': 0.9867\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Data augmentation parameters (from Paper 2)\n",
    "    'augmentation_params': {\n",
    "        'rotation_range': 90,        # 0-90 degrees\n",
    "        'horizontal_flip': True,\n",
    "        'vertical_flip': True,\n",
    "        'zoom_range': 0.2,           # Random magnification\n",
    "        'width_shift_range': 0.1,    # Random shifting\n",
    "        'height_shift_range': 0.1,\n",
    "        'fill_mode': 'nearest'\n",
    "    },\n",
    "    \n",
    "    # Visualization parameters\n",
    "    'plot_style': 'seaborn',\n",
    "    'figure_size': (12, 8),\n",
    "    'dpi': 100\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path_key in ['processed_data_path', 'saved_models_path', 'results_path']:\n",
    "    CONFIG[path_key].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"\\nBase path: {CONFIG['base_path'].resolve()}\")\n",
    "print(f\"Raw data path: {CONFIG['raw_data_path'].resolve()}\")\n",
    "print(f\"Number of models: {len(CONFIG['models'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_nifti_volume(header_file_path):\n",
    "    \"\"\"\n",
    "    Load a NIfTI volume from .hdr/.img file pair.\n",
    "    \n",
    "    Args:\n",
    "        header_file_path (str or Path): Path to .hdr file\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: 3D volume data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load using nibabel\n",
    "        img = nib.load(str(header_file_path))\n",
    "        volume_data = img.get_fdata()\n",
    "        return volume_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {header_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_representative_slices(volume, num_slices=4, axis=2):\n",
    "    \"\"\"\n",
    "    Extract representative 2D slices from 3D MRI volume.\n",
    "    Focuses on middle brain region (most informative for AD).\n",
    "    \n",
    "    Args:\n",
    "        volume (numpy.ndarray): 3D volume (H, W, D)\n",
    "        num_slices (int): Number of slices to extract\n",
    "        axis (int): Axis along which to slice (2=axial, 1=coronal, 0=sagittal)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of 2D numpy arrays\n",
    "    \"\"\"\n",
    "    if volume is None:\n",
    "        return []\n",
    "    \n",
    "    depth = volume.shape[axis]\n",
    "    \n",
    "    # Extract slices from middle 50% of volume (skip top and bottom)\n",
    "    start_idx = depth // 4\n",
    "    end_idx = 3 * depth // 4\n",
    "    \n",
    "    # Evenly spaced indices\n",
    "    slice_indices = np.linspace(start_idx, end_idx, num_slices, dtype=int)\n",
    "    \n",
    "    slices = []\n",
    "    for idx in slice_indices:\n",
    "        if axis == 0:  # Sagittal\n",
    "            slice_2d = volume[idx, :, :]\n",
    "        elif axis == 1:  # Coronal\n",
    "            slice_2d = volume[:, idx, :]\n",
    "        else:  # Axial (default)\n",
    "            slice_2d = volume[:, :, idx]\n",
    "        \n",
    "        slices.append(slice_2d)\n",
    "    \n",
    "    return slices\n",
    "\n",
    "\n",
    "def preprocess_slice(slice_2d, target_size=(224, 224), normalize=True, to_rgb=True):\n",
    "    \"\"\"\n",
    "    Preprocess a 2D MRI slice according to Paper 2 methodology:\n",
    "    1. Resize to target size\n",
    "    2. Normalize pixel values to [0, 1]\n",
    "    3. Convert to RGB (3-channel) format\n",
    "    \n",
    "    Args:\n",
    "        slice_2d (numpy.ndarray): 2D grayscale slice\n",
    "        target_size (tuple): Target (height, width)\n",
    "        normalize (bool): Whether to normalize to [0, 1]\n",
    "        to_rgb (bool): Whether to convert to 3-channel RGB\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed slice or None if slice is invalid\n",
    "    \"\"\"\n",
    "    # Handle NaN and infinite values\n",
    "    slice_2d = np.nan_to_num(slice_2d, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Ensure slice is 2D\n",
    "    if len(slice_2d.shape) > 2:\n",
    "        # If 3D, take the first 2D slice\n",
    "        slice_2d = np.squeeze(slice_2d)\n",
    "        if len(slice_2d.shape) > 2:\n",
    "            slice_2d = slice_2d[:, :, 0] if slice_2d.shape[2] == 1 else slice_2d[0, :, :]\n",
    "    \n",
    "    # Check if slice has valid dimensions (at least 2x2)\n",
    "    if slice_2d.shape[0] < 2 or slice_2d.shape[1] < 2:\n",
    "        return None\n",
    "    \n",
    "    # Normalize to [0, 255] range for uint8\n",
    "    slice_min = slice_2d.min()\n",
    "    slice_max = slice_2d.max()\n",
    "    if slice_max > slice_min:\n",
    "        slice_normalized = ((slice_2d - slice_min) / (slice_max - slice_min) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        slice_normalized = np.zeros_like(slice_2d, dtype=np.uint8)\n",
    "    \n",
    "    # Resize using cv2 (more robust than PIL for edge cases)\n",
    "    slice_resized = cv2.resize(slice_normalized, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Convert to RGB (3-channel) if needed\n",
    "    if to_rgb:\n",
    "        if len(slice_resized.shape) == 2:\n",
    "            slice_rgb = np.stack([slice_resized] * 3, axis=-1)\n",
    "        else:\n",
    "            slice_rgb = slice_resized\n",
    "    else:\n",
    "        slice_rgb = slice_resized\n",
    "    \n",
    "    # Normalize to [0, 1] if required\n",
    "    if normalize:\n",
    "        slice_final = slice_rgb.astype(np.float32) / 255.0\n",
    "    else:\n",
    "        slice_final = slice_rgb\n",
    "    \n",
    "    return slice_final\n",
    "\n",
    "\n",
    "def load_demographics(demographics_path):\n",
    "    \"\"\"\n",
    "    Load OASIS demographics file and extract CDR scores for labeling.\n",
    "    \n",
    "    Args:\n",
    "        demographics_path (str or Path): Path to OASIS_demographic.xlsx\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Demographics with Subject ID and CDR score\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(demographics_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_binary_label(cdr_score, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Convert CDR score to binary label.\n",
    "    \n",
    "    CDR (Clinical Dementia Rating) scale:\n",
    "    - 0 = No dementia (Non-Demented)\n",
    "    - 0.5 = Very mild dementia (Demented)\n",
    "    - 1.0 = Mild dementia (Demented)\n",
    "    - 2.0 = Moderate dementia (Demented)\n",
    "    - 3.0 = Severe dementia (Demented)\n",
    "    \n",
    "    Args:\n",
    "        cdr_score (float): CDR score\n",
    "        threshold (float): Threshold for classification\n",
    "        \n",
    "    Returns:\n",
    "        int: 0 (Non-Demented) or 1 (Demented)\n",
    "    \"\"\"\n",
    "    if pd.isna(cdr_score):\n",
    "        return None\n",
    "    return 1 if cdr_score >= threshold else 0\n",
    "\n",
    "\n",
    "print(\"Data processing functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def calculate_all_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"\n",
    "    Calculate all evaluation metrics as specified in Paper 2:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1-score\n",
    "    - Specificity\n",
    "    \n",
    "    Args:\n",
    "        y_true (array-like): True labels\n",
    "        y_pred (array-like): Predicted labels\n",
    "        y_pred_proba (array-like, optional): Prediction probabilities\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all metrics\n",
    "    \"\"\"\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'specificity': specificity,\n",
    "        'confusion_matrix': cm,\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn\n",
    "    }\n",
    "    \n",
    "    # Add AUC if probabilities provided\n",
    "    if y_pred_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        metrics['auc'] = auc_score\n",
    "        metrics['fpr'] = fpr\n",
    "        metrics['tpr'] = tpr\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_metrics(metrics, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Print evaluation metrics in a formatted way.\n",
    "    \n",
    "    Args:\n",
    "        metrics (dict): Dictionary of metrics from calculate_all_metrics\n",
    "        model_name (str): Name of the model\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} - Evaluation Metrics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:    {metrics['accuracy']*100:.2f}%\")\n",
    "    print(f\"Precision:   {metrics['precision']*100:.2f}%\")\n",
    "    print(f\"Recall:      {metrics['recall']*100:.2f}%\")\n",
    "    print(f\"F1-Score:    {metrics['f1_score']*100:.2f}%\")\n",
    "    print(f\"Specificity: {metrics['specificity']*100:.2f}%\")\n",
    "    if 'auc' in metrics:\n",
    "        print(f\"AUC:         {metrics['auc']:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  TN={metrics['tn']}, FP={metrics['fp']}\")\n",
    "    print(f\"  FN={metrics['fn']}, TP={metrics['tp']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "print(\"Evaluation metrics functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix with annotations.\n",
    "    \n",
    "    Args:\n",
    "        cm (numpy.ndarray): Confusion matrix\n",
    "        class_names (list): List of class names\n",
    "        title (str): Plot title\n",
    "        save_path (str, optional): Path to save figure\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar=True, square=True)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, model_name=\"Model\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy/loss curves.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Training history with keys 'train_acc', 'train_loss', 'val_acc', 'val_loss'\n",
    "        model_name (str): Name of the model\n",
    "        save_path (str, optional): Path to save figure\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    if 'train_acc' in history:\n",
    "        axes[0].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "    if 'val_acc' in history:\n",
    "        axes[0].plot(history['val_acc'], label='Validation', linewidth=2)\n",
    "    axes[0].set_title(f'{model_name} - Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend(loc='lower right')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    if 'train_loss' in history:\n",
    "        axes[1].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "    if 'val_loss' in history:\n",
    "        axes[1].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "    axes[1].set_title(f'{model_name} - Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend(loc='upper right')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(metrics, model_name=\"Model\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot ROC curve.\n",
    "    \n",
    "    Args:\n",
    "        metrics (dict): Metrics dictionary with 'fpr', 'tpr', 'auc'\n",
    "        model_name (str): Name of the model\n",
    "        save_path (str, optional): Path to save figure\n",
    "    \"\"\"\n",
    "    if 'fpr' not in metrics or 'tpr' not in metrics:\n",
    "        print(\"FPR and TPR not available in metrics\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(metrics['fpr'], metrics['tpr'], linewidth=2, \n",
    "             label=f\"AUC = {metrics.get('auc', 0):.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'{model_name} - ROC Curve', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sample_slices(images, labels, class_names, num_samples=10, title=\"Sample MRI Slices\"):\n",
    "    \"\"\"\n",
    "    Plot sample MRI slices with their labels.\n",
    "    \n",
    "    Args:\n",
    "        images (numpy.ndarray or torch.Tensor): Array of images\n",
    "        labels (numpy.ndarray or torch.Tensor): Array of labels\n",
    "        class_names (list): List of class names\n",
    "        num_samples (int): Number of samples to plot\n",
    "        title (str): Plot title\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy if needed\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = images.cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "    \n",
    "    indices = np.random.choice(len(images), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = images[idx]\n",
    "        label = labels[idx]\n",
    "        \n",
    "        # Handle different image formats\n",
    "        if len(img.shape) == 3 and img.shape[0] == 3:\n",
    "            # PyTorch format (C, H, W) - convert to (H, W, C)\n",
    "            display_img = np.transpose(img, (1, 2, 0))\n",
    "        elif len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "            # RGB image (H, W, C)\n",
    "            display_img = img\n",
    "        elif len(img.shape) == 3:\n",
    "            # Take first channel\n",
    "            display_img = img[0] if img.shape[0] < img.shape[-1] else img[:, :, 0]\n",
    "        else:\n",
    "            display_img = img\n",
    "        \n",
    "        axes[i].imshow(display_img, cmap='gray')\n",
    "        axes[i].set_title(f\"{class_names[int(label)]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Visualization functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation setup loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def create_data_augmentation():\n",
    "    \"\"\"\n",
    "    Create transforms composition with augmentation parameters from Paper 2.\n",
    "    \n",
    "    Returns:\n",
    "        torchvision.transforms.Compose: Configured data augmentation transforms\n",
    "    \"\"\"\n",
    "    aug_params = CONFIG['augmentation_params']\n",
    "    \n",
    "    # PyTorch transforms for data augmentation\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(degrees=(0, aug_params['rotation_range'])),\n",
    "        transforms.RandomHorizontalFlip(p=0.5 if aug_params['horizontal_flip'] else 0),\n",
    "        transforms.RandomVerticalFlip(p=0.5 if aug_params['vertical_flip'] else 0),\n",
    "        transforms.RandomAffine(degrees=0, \n",
    "                                translate=(aug_params['width_shift_range'], aug_params['height_shift_range']),\n",
    "                                scale=(1-aug_params['zoom_range'], 1+aug_params['zoom_range'])),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # No augmentation for validation/test\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    return train_transforms, test_transforms\n",
    "\n",
    "\n",
    "# Custom Dataset class for augmentation\n",
    "class AugmentedDataset(Dataset):\n",
    "    \"\"\"Custom Dataset with augmentation support.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert from PyTorch format (C, H, W) to PIL format (H, W, C)\n",
    "        if len(image.shape) == 3 and image.shape[0] in [1, 3]:\n",
    "            # Already in (C, H, W) format, convert to (H, W, C)\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "        \n",
    "        # Convert to uint8 for transforms if needed\n",
    "        if image.dtype != np.uint8:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        \n",
    "        # Remove single channel dimension if grayscale\n",
    "        if image.shape[-1] == 1:\n",
    "            image = image.squeeze(-1)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # Convert to tensor if no transform\n",
    "            if not isinstance(image, torch.Tensor):\n",
    "                # Convert back to (C, H, W) format for PyTorch\n",
    "                if len(image.shape) == 3:\n",
    "                    image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "                else:\n",
    "                    image = torch.from_numpy(image).unsqueeze(0).float() / 255.0\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Memory-mapped dataset for large files\n",
    "class MemoryMappedDataset(Dataset):\n",
    "    \"\"\"Memory-efficient dataset using memory-mapped numpy arrays.\"\"\"\n",
    "    \n",
    "    def __init__(self, X_path, y_path, transform=None, normalize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_path: Path to .npy file with images\n",
    "            y_path: Path to .npy file with labels\n",
    "            transform: Optional transform to apply\n",
    "            normalize: Whether to normalize to [0, 1]\n",
    "        \"\"\"\n",
    "        # Load labels (small, can fit in memory)\n",
    "        self.labels = np.load(y_path)\n",
    "        \n",
    "        # Memory-map the image data (doesn't load into RAM)\n",
    "        self.images = np.load(X_path, mmap_mode='r')\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load single image from memory-mapped file\n",
    "        image = np.array(self.images[idx])  # Load only this one image\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Normalize if needed\n",
    "        if self.normalize and image.dtype == np.uint8:\n",
    "            image = image.astype('float32') / 255.0\n",
    "        \n",
    "        # Convert to PyTorch format (C, H, W) if needed\n",
    "        if len(image.shape) == 3 and image.shape[-1] in [1, 3]:\n",
    "            # (H, W, C) -> (C, H, W)\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        \n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            # Transform expects (H, W, C), so convert back\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "            if image.dtype != np.uint8:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # Convert to tensor\n",
    "            image = torch.from_numpy(image).float()\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "print(\"Data augmentation setup loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PAPER 2 UTILITIES AND CONFIGURATION - SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ All libraries imported successfully\n",
      "✓ Configuration parameters loaded\n",
      "✓ Data processing functions defined\n",
      "✓ Evaluation metrics functions defined\n",
      "✓ Visualization functions defined\n",
      "✓ Data augmentation configured\n",
      "\n",
      "Ready to proceed with:\n",
      "  - Notebook 01: Data Preparation\n",
      "  - Notebooks 02-06: Model Implementations\n",
      "  - Notebook 07: Results Comparison\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PAPER 2 UTILITIES AND CONFIGURATION - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✓ All libraries imported successfully\")\n",
    "print(\"✓ Configuration parameters loaded\")\n",
    "print(\"✓ Data processing functions defined\")\n",
    "print(\"✓ Evaluation metrics functions defined\")\n",
    "print(\"✓ Visualization functions defined\")\n",
    "print(\"✓ Data augmentation configured\")\n",
    "print(\"\\nReady to proceed with:\")\n",
    "print(\"  - Notebook 01: Data Preparation\")\n",
    "print(\"  - Notebooks 02-06: Model Implementations\")\n",
    "print(\"  - Notebook 07: Results Comparison\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
